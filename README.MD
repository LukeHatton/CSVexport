#### 1.需要解决limit查询速度缓慢的问题

因为使用limit做分页的话，它先是逐行找到目标行索引，然后才开始进行查询，这样速度就很慢了，在数据量较大的情况下会达到几百ms。

在索引连续时，先使用`where`定位索引，然后再通过limit查询，会快很多，因为`where`定位是个位数ms级别的。**不过，这要求索引连续**，在物理删除数据的业务中无法使用

**所以，需要找一种办法，能够在索引不连续的情况下快速进行limit查询**

> 看中文网站并没有特别好的解决方案，都是基于主键连续的办法，对于不连续主键也是想办法将其转为连续的，对于不允许随意操作数据的开发要求来说不可行。
>
> **应该可以用`between and`做分页，因为业务并没有特别严格的分页数据查询要求，只要每批次查询出来的数据大致符合就可以**
>
> 但是使用`between and`分页要求主键必须是自增的，这点必须在工作数据库中确认一下
>
> 文件写入总是不全，是不是被覆盖了？总是写到989954这一行就停止写入了
>
> 改了下分页值，现在写到997525了
>
> 又改了一下`BufferedOutputStream`的缓冲区大小，现在未写入数据也变多了，确定了是最后一个缓冲区的数据没有被写入。
>
> 现在每写一行数据就清一次缓冲区(flush)，但是这样会造成写入效率降低
>
> 通过在工具类方法代码中最后调用一次`flush`,解决了数据不完整问题。**这应该是因为调用者不知道工具类将输出流包装成了`BufferedOutputStream，`因此在用户代码中调用`flush()`也就不知道要去清空缓冲区**

------

#### 2.改成异步读写

现在的代码实现是同步读写的，也就是只有数据库读完了，才能写入文件。这大大降低了文件导出效率。用异步代码重写

> 线程池:`ScheduledExecutorService`
>
> 队列:`ConcurrentSkipListSet`
>
> 考虑换一种队列实现，因为并不是真的需要排序，只是需要把任务或数据像入栈一样插入队列就可以了，需要一个FIFO线程安全的队列
>
> 如果是定时执行，就必须设置定期检查时间，这个时间太短的话对系统资源也是一种空耗。最好能将线程池和任务队列用发布订阅或观察者模式结合使用
>
> 出现了问题：单线程线程池执行多任务时，任务是会积压，还是会挤掉前一个任务？
>
> 不用担心上面的问题，实测是会积压的。当然还是要去了解一下实现原理
>
> 因为采用了异步写操作，需要对写入进行一下同步，否则无法得知文件是否全部写入完成
>
> 很简单，使用CountDownLatch进行同步

再次思考此实现路径,其实缺点主要还是在文件导出比较慢上,文件压缩其实很快,大概只是文件导出的十分之一,及时是从数据流直接写入压缩文件,还是没有本质性提高速度.

而且,大数据量文件导出,肯定不是实时导出的,直接写入压缩文件节约的那一点时间也就无关紧要了.

------

#### 3.不生成CSV中间文件,数据库读出后直接写入压缩文件

现在的实现相当于是每批次数据都向ZIP文件中写入一个新的`ZipEntry`

重新考虑这个实现方式,感觉有些过于定制化了,这种实现方式的扩展性很差,且修改难度很高,**完全违背了“对扩展开放,对修改封闭”的原则**
